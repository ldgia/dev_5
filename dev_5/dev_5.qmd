---
editor: visual
format: 
  html:
    theme: cosmo
---

```{r}
#| message: false
library("tidyverse")
library("fpp3")
library("cowplot")
library("plotly")
library(dplyr)
library(ggplot2)
library(lubridate)
library(timetk)

# Setup for the plotly charts (# FALSE returns ggplots)
interactive <- FALSE
theme_set(theme_bw())
```

```{r}
#| warning: false
hawai <- read_csv("data/hawai_change.csv")


#round_date(time # choisit unite) pi apres year_month
```

# Prétraitement des données

```{r}
hawai <- hawai |> 
  mutate(time = (datetime = date_decimal(time)))


hawai<- hawai |> 
  mutate(time = yearmonth(time))

hawai_time <- hawai |> 
 tsibble()

```

```{r}
#| label: fig-serie_tempo
#| fig-cap: "Série temporelle de l'évolution de la concentration du dioxyde de carbone (CO2) de 1958 à 2001 à Hawaii"
hawai_time |> 
 plot_time_series(as_date(time), CO2)
```

## Analyse de la série temporelle

Pour débuter, une analyse visuelle de la série temporelle peut aider à détecter différents comportement des données. À la @fig-serie_tempo, il est possible de remarquer une tendance à la hausse de nos données. La concentration en dioxyde de carbone augmente durant la période de temps, allant de 1958 à 2001. C'est une tendance à la hausse.

Il semble aussi avoir des variations saisonnières :

```{r}
CO2_monthly <- hawai |> 
  mutate(time = yearmonth(as.character(time))) |> 
  group_by(time) |> summarise(
    mean_CO2 = mean(CO2)
  ) |> 
   tsibble()
```

::: call-out
Avec ggseason tu moyen de pas toute mettre les années? la lecture est difficile en pomal sinon

REp: utilise polar + ui du bas
:::

```{r}
#| label: fig-season_fluactuation
#| fig-cap: Fluctuation saisonnière du flux de dioxyde de carbone à Hawaii entre 1958 et 2001
Sys.setlocale("LC_ALL", "fr_CA")
CO2_monthly |> 
gg_season(mean_CO2, polar = TRUE)
```

Comme les lignes se superposent, la lecture peut être difficile. Voici un graphique qui représente les années terminant par 0 et par 5 comprise en 1958 et 2001, pour faciliter la lecture:

```{r}
#| label: fig-season_fluactuation_slice
#| fig-cap: Fluctuation saisonnière du flux de dioxyde de carbone à Hawaii pour quelques années situées entre 1958 et 2001
CO2_monthly |> 
  mutate(year = year(time),
         month = month(time, label = TRUE)) |> 
  filter(year %% 10 == 5 | year %% 10 == 0) |> 
  ggplot(aes(x = month, y = mean_CO2, group = year, color = year)) +
  geom_line() +
  scale_colour_gradientn(colours = rainbow(5))+
  labs(x = "Mois", y = "Concentration en dioxyde de carbone", color = "Année") +
  theme_bw()

```

Des fluactions saisonnières sont aussi apparente, la concentration en dioxyde de carbone est plus forte au mois de mais comme il est possible de voir à la @fig-season_fluactuation et à la @fig-season_fluactuation_slice. Le concentration en dioxyde de carbone atteint des valeurs plus faibles au mois d'octobre. Il ne semble pas y avoir de fluctuation cyclique présente dans les variations de la concentration en dioxyde de carbone dans les données étudiées.

```{r}
#| label: fig-graph_diagnostic
#| fig-cap: Graphique pour l'analyse visuelle de la série temporelle
plot_grid(ACF(hawai_time, y = CO2, lag_max = 24) |> autoplot()+labs(y = NULL),
  gg_lag(hawai_time, geom = "point", lags = c(1:12))+ labs(x = NULL, y = NULL))
 

# pour le ag lag : T (nb d'obs.) / 5 max, ou le nombre de cycles

```

::: call-out
Pour choisir le lag dans le test de Ljung, est-ce qu'on regarde notre graphique d'autocorrelation et si un a un peak a un endroit par exemple apres 12 periode de temps, on met ce lag la?

# pour le ag lag : T (nb d'obs.) / 5 max, ou le nombre de cycles

meme principle pour ACF lag_max on met quoi?

# pour le ag lag : T (nb d'obs.) / 5 max, ou le nombre de cycles
:::

```{r}
#| label: tbl-ljung_test
#| tbl-cap: Test de ljung sur la série temporelle du flux de dioxyde de carbone à Hawaii entre 1958 et 2001
ljung_test<-hawai_time |> 
  features(CO2, ljung_box, lag = 48)  |> # changer le lag
  rename(statistique = lb_stat, `p-value` = lb_pvalue)
knitr::kable(ljung_test, align = "c")
```

```{r}
#| eval: false
hawai_time |> 
 plot_acf_diagnostics(time, CO2)
```

# Prévision

Pour débuter, il faut séparer les données en pour un ensemble d'entrainement du modèle, et un ensemble pour les tests.

```{r}
row_hawai_time <- nrow(hawai_time)
data <-  as.integer(row_hawai_time*0.7)
hawai_time_train <- hawai_time |> 
  slice(1:data)
hawai_time_test <- hawai_time |> 
  slice((data+1):row_hawai_time)
```

Comme je ne suis pas un expert en la matière, il me semble risqué de faire un choix de modèle pour effectuer les prédictions. Je vais donc en utiliser deux, puis les comparer, pour ensuite faire mes prédictions. Les méthodes SES et ARIMA seront utilisées. Comme le jeu de données n'est pas significativement gros, des méthodes automatisées seront utilisée.

## SES

::: call-out
tu moyen de pas utilsier autoplot pour faire les graphique

AUTOLAYER
:::

Pour la méthode SES, la fonction ETS permet de sélectionner le meilleur modèle SES en minimisant le AICc. L'AICc permet de sélectionner le modèle qui explique l'adéquation des données (dans le cas présent des concentrations de CO2), en minimisant le nombre de paramètre utilisé pour construire le modèle. Cette mesure permet de comparer la précision du modèle, en pénalisant l'ajout de variables.

```{r}
projected <- nrow(hawai_time_test)

CO2_model_ses <- hawai_time_train |> 
  model(ETS(CO2))
report(CO2_model_ses)
```

Le modèle choisit est ETS(A,A,A), ce qui signifie que le type d'erreur, la tendance et la saisonnalité dont de type additifs. Le type d'erreur additid signifie que les erreurs sont indépendantes de la temporalité. C'est aussi sans surprise que la tendance change de manière linéaire, ce qui est visible préalablement. De plus, la saisonnalité des données étaient aussi préalablement observés.

Il est possible de suivre l'évolution des différentes composantes du modèle à travers le temps:

::: call-out
Les barres grises dans la decomposition ca veut dire quoi exactement? Par exemple, pourquoi la slope est si importante?
:::

```{r}
#| label: fig-graph_diagnostic_ses
#| fig-cap: Graphique pour l'analyse visuelle de la série temporelle
components(CO2_model_ses) |> 
  autoplot()
```

Le premier graphe en haut présent les valeurs observées, le deuxième présente l'estimation de la tendance, Le troisième présente les changements de la tendance au fil du temps, le quatriéme présente une estimation de la saisonnalité et le cinquième présente ce qui ne peut pas être expliqué par le modèle.

Slope negligable, plus petit la barre plus que ca influence

Le modèle prédit une tendance à la hausse. De plus, la composante slope permet d'expliquer une grande partie de la variabilité des données. Ceci identique que les changements dans la tendances expliquent grandement le modèle prédit. Comme les valeurs sont relativements petites, le changement s'effectue sur une longue période de temps, à petite échelle. La saisonnalité est bien présente, mais elle n'explique pas la tendance générale des données. L'erreur est très faible, comme le graphique remainder nos le montre.

Il est possible de créer une projection de nos données pour voir comment le modèle prédit les données dans le temps:

```{r}
#| label: fig-graph_projection_ses
#| fig-cap: Graphique de la série temporelle originales (en noir) avec les données prédites pour le modèle SES (en bleu). Les données prédites sont de novembre 1988 à décembre 2001
CO2_ses_fc <- CO2_model_ses|> forecast(h = projected)
CO2_ses_fc |>
  autoplot(hawai_time, fill = "blue")
```

En comparant les lignes en bleu est assez similaire à la ligne en noir, qui représente les données reelles. Le modèle semble faire un prédiction efficace, des analyses statistiques peuvent le confirmer:

```{r}
#| label: tbl-accuracy_ses
#| tbl-cap: Vérification de l'exactitude du modèle
knitr::kable(accuracy(CO2_ses_fc, hawai_time) |> 
               select(-c(.model, .type, ME, RMSSE, ACF1)), align = "c")
```

Débutons par décrire les colonnes du tableau qui seront abordé:

RMSE: Erreur quadratique moyenne:La racine carrée de la moyenne des erreurs quadratiques des données préjetées. MAE: Erreur moyenne absolu, calcule de la différence moyenne des valeurs prédites et les données originales MAPE: Erreur Absolue Moyenne en Pourcentage, le pourcentage d'erreur absolu en moyenne pour chaque période de temps moins les valeurs réelles divisées par les valeurs réelles. MASE: Comparaison de l'erreur absolue moyenne de la prévision à l'erreur absolue moyenne d'une prévision naïve Dans tout les cas, des valeurs plus faibles sont souhaitables. L'objectif est de miniser les erreurs, et donc des modèles plus exactes.

Les données pour le modèle SES sont relativement faibles. L'erreur quadratique est la valeur la plus forte, ce qui signifie que les erreurs sont distribuées dans les valeurs prédites. La valeur de MASE n'est pas très loin de 0, donc un modèle naif (prédiction seulement avec la donnée précédante) aurait pu faire une prédiction des valeurs similaire à notre modèle.

Un diagnostique visuel des résidus peut aussi être effectué:

```{r}
#| label: fig-graph_residuals_ses
#| fig-cap: Analyse des résidus du modèle SES
gg_tsresiduals(CO2_model_ses)
aug<-augment(CO2_model_ses)
shapiro.test(aug$.innov)
augment(CO2_model_ses) |> features(.innov, ljung_box)
```

::: call-out
Pour analyse des residus: -comment savoir si ca distingue du bruit blanc (le graphique et le test stat, mais je ne comprend pas trop bien, surtout comment choisir le lag) -pour shapiro, pour moi ma methode est pas bonne, car jai une pvalue super faible et le graphique et proche de la normale...

-For both\
Q and\
Q ∗ , the results are not significant (i.e., the\
p -values are relatively large). Thus, we can conclude that the residuals are not distinguishable from a white noise series. un pvalue faible dans un test de ljung ca veut dire que ce nest pas du bruit blanc? -comment savoir si c'est des valeurs abberantes les residus? -est ce que les axes ont une importance, par exemple, les axes dans mon cas presente des tres petites valeurs donc cest proche de 0
:::

## ARIMA

Tout comme la fonction ETS, la fonction arima permet de trouver un modèle en spécificiant automatiquement les paramètres p, d et q. Ca diminue les erreurs.

::: call-out
Pour la fonction ARIMA est-ce quon ai certain que sa trouve le meilleur modele?
:::

```{r}
CO2_model_arima <- hawai_time_train |> model(ARIMA(CO2, 
stepwise = FALSE, approximation = FALSE))
CO2_arima_fc<-CO2_model_arima |> forecast(h = projected)
```

```{r}
#| label: fig-graph_projection_arima
#| fig-cap: Graphique de la série temporelle originales (en noir) avec les données prédites pour le modèle SES (en bleu). Les données prédites sont de novembre 1988 à décembre 2001
CO2_arima_fc|> autoplot(hawai_time, fill = "blue")  
```

Il est possible de voir que les prédictions semblent assez proche de la réalité, mais lègerement supérieur aux données reelles.

::: {call.out}
ARIMA(0,1,3)(2,1,1)\[12\] ca veut dire quoi ca, la deuxieme parenthese c'est la saisonalite, 12 le lag
:::

```{r}
report(CO2_model_arima)
```

```{r}
#| label: tbl-accuracy_
#| tbl-cap: Vérification de l'exactitude du modèle ARIMA
knitr::kable(accuracy(CO2_model_arima) |> 
               select(-c(.model, .type, ME, RMSSE, ACF1)), align = "c")
```

```{r}
gg_tsresiduals(CO2_model_arima)
aug<-augment(CO2_model_arima)
shapiro.test(aug$.innov)
augment(CO2_model_arima) |> features(.innov, ljung_box)
```

::: cal-out
Mon shapiro test est encore plus petit que 0.05 , mais cest tellement bien distribué c impossible

AR i MA
:::

# Comparaison des modèles
